# Default use the NVIDIA official image with PyTorch 2.3.0
# https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/index.html
# ARG BASE_IMAGE=nvidia/cuda:11.4.3-runtime-ubuntu20.04
ARG BASE_IMAGE=pytorch/pytorch:2.1.2-cuda11.8-cudnn8-runtime
FROM ${BASE_IMAGE}

# Define environments
ENV MAX_JOBS=4
ENV FLASH_ATTENTION_FORCE_BUILD=TRUE
ENV VLLM_WORKER_MULTIPROC_METHOD=spawn

# Define installation arguments
ARG INSTALL_BNB=false
ARG INSTALL_VLLM=false
ARG INSTALL_DEEPSPEED=false
ARG INSTALL_FLASHATTN=false
ARG INSTALL_LIGER_KERNEL=false
ARG INSTALL_HQQ=false
ARG INSTALL_EETQ=false
ARG PIP_INDEX=https://pypi.org/simple

ARG UID=11132
ARG GID=11133
ENV HOME=/home/llm-apps
RUN addgroup --gid $GID llm-adm && adduser --uid $UID --ingroup llm-adm --disabled-password -q --gecos llm llm-apps

# Set the working directory
ARG APP_DIR=/app
WORKDIR $APP_DIR

COPY . /app
RUN chown -R $UID:$GID $APP_DIR
USER $UID:$GID

# Install the requirements
COPY requirements.txt /app
RUN python -m venv $APP_DIR/.venv && . $APP_DIR/.venv/bin/activate && \
    pip config set global.index-url "$PIP_INDEX" && \
    pip config set global.extra-index-url "$PIP_INDEX" && \
    python -m pip install --no-cache-dir --upgrade pip && \
    python -m pip install --no-cache-dir -r requirements.txt -i https://download.pytorch.org/whl/cu118

# Copy the rest of the application into the image

# Install the LLaMA Factory
RUN python -m venv $APP_DIR/.venv && . $APP_DIR/.venv/bin/activate && \
    pip install --no-cache-dir -i https://download.pytorch.org/whl/cu118 -e "."

# Rebuild flash attention
RUN python -m venv $APP_DIR/.venv && . $APP_DIR/.venv/bin/activate && \
    pip uninstall -y transformer-engine flash-attn && \
    if [ "$INSTALL_FLASHATTN" == "true" ]; then \
        pip uninstall -y ninja && pip install ninja && \
        pip install --no-cache-dir flash-attn --no-build-isolation; \
    fi

# Set up volumes
VOLUME [ "/$HOME/.cache/huggingface", "/$HOME/.cache/modelscope", "/app/data", "/app/output" ]

# Expose port 7860 for the LLaMA Board
ENV GRADIO_SERVER_PORT 7860
EXPOSE 7860

# Expose port 8000 for the API service
ENV API_PORT 8000
EXPOSE 8000

ENTRYPOINT ["/bin/sh", "-c", "/app/run.sh"]
